{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa652e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Sequential, layers, Input, datasets, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "path = \"C:/Users/Lucia/Desktop/statistical learning/final/raw-img\"\n",
    "\n",
    "translate = {\n",
    "    \"cane\": \"dog\",\n",
    "    \"cavallo\": \"horse\",\n",
    "    \"elefante\": \"elephant\",\n",
    "    \"farfalla\": \"butterfly\",\n",
    "    \"gallina\": \"chicken\",\n",
    "    \"gatto\": \"cat\",\n",
    "    \"mucca\": \"cow\",\n",
    "    \"pecora\": \"sheep\",\n",
    "    \"scoiattolo\": \"squirrel\",\n",
    "    \"ragno\": \"spider\"\n",
    "}\n",
    "\n",
    "data = {\"imgpath\": [], \"labels\": []}\n",
    "\n",
    "for img_class in os.listdir(path):\n",
    "     folderpath = os.path.join(path, img_class)\n",
    "     filelist = os.listdir(folderpath)\n",
    "\n",
    "     english_label = translate.get(img_class, img_class)  \n",
    "     data['labels'] += [english_label] * len(filelist)\n",
    "     data['imgpath'] += [os.path.join(folderpath, file) for file in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Number of images contaned in the dataset:\\n\", df.shape[0])\n",
    "print(\"_______________________________________\")\n",
    "print(\"Number of null values:\\n \", df.isnull().sum())\n",
    "print(\"_______________________________________\")\n",
    "print(\"Number of unique values:\\n\", df.nunique())\n",
    "print(\"_______________________________________\")\n",
    "counts = df['labels'].value_counts()\n",
    "print(\"Number of images for every category:\\n \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing:\n",
    "# Encode string labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"encoded_labels\"] = label_encoder.fit_transform(data[\"labels\"])\n",
    "\n",
    "# Load images and convert them to NumPy arrays using TensorFlow\n",
    "image_data = [tf.image.decode_jpeg(tf.io.read_file(img_path), channels=3) for img_path in data['imgpath']]\n",
    "image_data = [tf.image.resize(img, (32, 32)) for img in image_data]\n",
    "image_data = [tf.cast(img, tf.float32) / 255.0 for img in image_data]\n",
    "\n",
    "# Ensure all images have the same dimensions\n",
    "min_width = min(img.shape[0] for img in image_data)\n",
    "min_height = min(img.shape[1] for img in image_data)\n",
    "image_data = [tf.image.resize_with_crop_or_pad(img, min_width, min_height) for img in image_data]\n",
    "\n",
    "# Convert labels to NumPy array\n",
    "label_data = np.array(data[\"encoded_labels\"])\n",
    "\n",
    "# Splitting the dataset into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_data, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transforming them into numpy array\n",
    "tr_x = np.array(X_train)\n",
    "tr_y = np.array(y_train)\n",
    "te_x = np.array(X_test)\n",
    "te_y = np.array(y_test)\n",
    "\n",
    "def preprocess(x, y):\n",
    "  x = tf.cast(x, tf.float32)/255.\n",
    "  y = tf.cast(y, tf.int32)\n",
    "  return x, y\n",
    "\n",
    "tr_ds = tf.data.Dataset.from_tensor_slices((tr_x, tr_y))\n",
    "te_ds = tf.data.Dataset.from_tensor_slices((te_x, te_y))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "tr_ds = tr_ds.map(preprocess).shuffle(len(tr_ds)).batch(batch_size = BATCH_SIZE)\n",
    "te_ds = te_ds.map(preprocess).batch(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8bdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN with dense layers\n",
    "\n",
    "EPOCH = 100\n",
    "LEARNING_RATE = 3e-4\n",
    "\n",
    "# define the model\n",
    "model_dense = Sequential([\n",
    "  layers.InputLayer(input_shape=(32,32,3)),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(units=512, activation='relu'),\n",
    "  layers.Dense(units=256, activation='relu'),\n",
    "  layers.Dense(units=128, activation='relu'),\n",
    "  layers.Dense(units=32, activation='relu'),\n",
    "  layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43103b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and fit the model\n",
    "model_dense.compile(\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer = optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "  metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history_dense = model_dense.fit (tr_ds, validation_data = te_ds, epochs = EPOCH,\n",
    "verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN with dropout\n",
    "# define the model\n",
    "model_dropout = Sequential([\n",
    "  layers.InputLayer(input_shape=(32,32,3)),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(units=512, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(units=256, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(units=128, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(units=64, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(units=34, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4270eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and fit the model\n",
    "model_dropout.compile(\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer = optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "  metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history_dropout = model_dropout.fit (tr_ds, validation_data = te_ds, epochs =\n",
    "EPOCH, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391de2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses and accuracies\n",
    "\n",
    "# Dense model\n",
    "acc_dense = history_dense.history[\"accuracy\"]\n",
    "val_acc_dense = history_dense.history[\"val_accuracy\"]\n",
    "loss_dense = history_dense.history[\"loss\"]\n",
    "val_loss_dense = history_dense.history[\"val_loss\"]\n",
    "\n",
    "# Dropout model\n",
    "acc_dropout = history_dropout.history[\"accuracy\"]\n",
    "val_acc_dropout = history_dropout.history[\"val_accuracy\"]\n",
    "loss_dropout = history_dropout.history[\"loss\"]\n",
    "val_loss_dropout = history_dropout.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creating an ImageDataGenerator with data augmentation settings\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.4\n",
    "    shear_range=0.1\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f0909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data generator on the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Creating the augmented training and test sets :\n",
    "tr_aug = datagen.flow(tr_x, tr_y, batch_size=128)\n",
    "te_aug = datagen.flow(te_x, te_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "conv_model = Sequential([\n",
    "    layers.InputLayer(input_shape=(32 ,32 ,3)),\n",
    "    layers.Conv2D(64, kernel_size=3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, kernel_size=3, padding=\"valid\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile\n",
    "conv_model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics = [\"accuracy\"])\n",
    "\n",
    "# Fit\n",
    "conv_fit = conv_model.fit(tr_aug, validation_data = te_aug, epochs=EPOCH, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuarcy and loss\n",
    "acc_conv = conv_fit.history[\"accuracy\"]\n",
    "val_acc_conv = conv_fit.history[\"val_accuracy\"]\n",
    "loss_conv = conv_fit.history[\"loss\"]\n",
    "val_loss_conv = conv_fit.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ad391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 1\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCH), acc_dense, label=\"Training Accuracy\")\n",
    "plt.plot(range(EPOCH), val_acc_dense, label=\"Validation Accuracy\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCH), loss_dense, label = \"Training Loss\")\n",
    "plt.plot(range(EPOCH), val_loss_dense, label = \"Validation Loss\")\n",
    "plt.legend(loc = \"lower left\")\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.savefig(\"f1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1114ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 2\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCH), acc_dropout, label=\"Training Accuracy\")\n",
    "plt.plot(range(EPOCH), val_acc_dropout, label=\"Validation Accuracy\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCH), loss_dropout, label = \"Training Loss\")\n",
    "plt.plot(range(EPOCH), val_loss_dropout, label = \"Validation Loss\")\n",
    "plt.legend(loc = \"lower left\")\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.savefig(\"f2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 3\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCH), acc_conv, label=\"Training Accuracy\")\n",
    "plt.plot(range(EPOCH), val_acc_conv, label=\"Validation Accuracy\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCH), loss_conv, label = \"Training Loss\")\n",
    "plt.plot(range(EPOCH), val_loss_conv, label = \"Validation Loss\")\n",
    "plt.legend(loc = \"lower left\")\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.savefig(\"f3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d06c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 4\n",
    "sample = random.sample(range(len(data['imgpath'])), 5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
    "for i, idx in enumerate(sample):\n",
    "    img_path = data['imgpath'][idx]\n",
    "    img = Image.open(img_path)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'Class: {data[\"labels\"][idx]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.savefig('fB1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fba199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 5\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
    "\n",
    "for i, idx in enumerate(sample):\n",
    "    img = image_data[idx].numpy() \n",
    "    label = label_encoder.inverse_transform([label_data[idx]])[0]\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'Class: {label}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.savefig('fB2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 6\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=df, x='labels', order=df['labels'].value_counts().index, palette='pastel')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.savefig('fB3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cacb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 7\n",
    "augmented_images = []\n",
    "num_images_to_display = 5\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    # Extraction of reconstructed images\n",
    "    batch = next(tr_aug)\n",
    "    augmented_image = batch[0][0]\n",
    "    augmented_images.append(augmented_image)\n",
    "    \n",
    "    # Showing transformed images\n",
    "    plt.figure(figsize=(10 , 5))\n",
    "    for i in range(num_images_to_display):\n",
    "        plt.subplot(1, num_images_to_display, i + 1)\n",
    "        plt.imshow(augmented_images[i])\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
